{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bb32b3",
   "metadata": {},
   "source": [
    "# Supplemental Code for \"Transductive conformal inference with adaptive scores\" by U. Gazin, G. Blanchard, E. Roquain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c593a4",
   "metadata": {},
   "source": [
    "## Disclaimer on the packages\n",
    "\n",
    "You need to download the four following packages before running the code. \n",
    "Files jdot.py, classif.py, procedure.py and algo.py are not from this paper. \n",
    "\n",
    "jdot.py and classif .py can be found in the github page https://github.com/rflamary/JDOT/tree/master and is the implementation of the methods proposed by N. Courty, R. Flamary, A. Habrard, A. Rakotomamonjy, in \"Joint Distribution Optimal Transportation for Domain Adaptation\" published in Neural Information Processing Systems (NIPS), 2017.\n",
    "\n",
    "procedure.py and algo.py can be found in the github page https://github.com/arianemarandon/adadetect#machine-learning-meets-fdr for the implementation and is the implementation of the methods proposed by Ariane Marandon, Lihua Lei, David Mary and Etienne Roquain in the paper \"Adaptive novelty detection with false discovery rate guarantee\", to appear in Annals of Statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca28fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "import statsmodels as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml \n",
    "from sklearn.ensemble import RandomForestClassifier,IsolationForest\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916bb014",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Procedure of Transfer Learning from:\n",
    "###          N. Courty, R. Flamary, A. Habrard, A. Rakotomamonjy, \n",
    "###         \"Joint Distribution Optimal Transportation for Domain Adaptation\"\n",
    "\n",
    "# Go to https://github.com/rflamary/JDOT/tree/master for the implementation\n",
    "\n",
    "from jdot import jdot_krr\n",
    "gamma=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b6a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AdaDetect Procedure from:\n",
    "###          Ariane Marandon, Lihua Lei, David Mary and Etienne Roquain,\n",
    "###          \"Machine learning meets false discovery rate\"\n",
    "\n",
    "# Go to https://github.com/arianemarandon/adadetect#machine-learning-meets-fdr for the implementation. \n",
    "\n",
    "\n",
    "\n",
    "from procedure import AdaDetectERM ,AdaDetectDE\n",
    "from algo import BH, EmpBH, adaptiveEmpBH, compute_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining OneClass Classifier\n",
    "\n",
    "class OCC(object):\n",
    "    \n",
    "    def __init__(self, scoring_fn):\n",
    "        self.null = scoring_fn \n",
    "    \n",
    "    def fit(self, x_train, x_null_train):\n",
    "        self.null.fit(x_null_train)\n",
    "    \n",
    "    def score_samples(self, x): \n",
    "        return -self.null.score_samples(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting colors for Graphics\n",
    "\n",
    "colors_blindness = sns.color_palette(\"colorblind\")\n",
    "\n",
    "color_train = colors_blindness[8]\n",
    "color_cal = colors_blindness[4]\n",
    "color_test = colors_blindness[7] #(0,0,0) #colors_blindness[4]\n",
    "\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{bm} \\usepackage{amsfonts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e15e5",
   "metadata": {},
   "source": [
    "# Simulation of conformal $p$-values: $P_{n,m}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226a7ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Distrib_EmpiricalPvalues(n):\n",
    "    U=stat.dirichlet.rvs(alpha=np.ones(n+1))[0]\n",
    "    Val=(np.arange(n+1)+1)/(n+1)\n",
    "    \n",
    "\n",
    "    DistribCond=stat.rv_discrete(values=(Val,U))\n",
    "    return DistribCond\n",
    "\n",
    "def Simu_EmpiricalPvalues(n,m,N=1):\n",
    "    \n",
    "    T=np.zeros((N,m))\n",
    "    for i in range(N):\n",
    "        DistribCond=Distrib_EmpiricalPvalues(n)\n",
    "        T[i]=DistribCond.rvs(size=m)\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b00bee",
   "metadata": {},
   "source": [
    "## Illustration of the PÃ³lya urn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96629f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConditionnalLaw(l,VectCount):\n",
    "    Values=np.arange(1,l+2)\n",
    "    ProLaw=(VectCount+1)/(np.sum(VectCount)+(l+1))\n",
    "    return stat.rv_discrete(name='Conditionnal Law',values=(Values,ProLaw))\n",
    "\n",
    "\n",
    "def UpdatingPValues(l,VectCount,UpdatePValue=False,P=np.array([])):\n",
    "    NewPValueLaw=ConditionnalLaw(l,VectCount)\n",
    "    p=NewPValueLaw.rvs(size=1)\n",
    "    \n",
    "    VectCount[p-1]+=1\n",
    "    \n",
    "    if UpdatePValue:\n",
    "        P.append(p)\n",
    "    \n",
    "    return(VectCount,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab49af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphicalRepresentation(l,VectCount,HightBar=False,m=0,SaveFig=False):\n",
    "    x=np.arange(1,l+2)\n",
    "    t=int(np.sum(VectCount))\n",
    "    tStr=str(t)\n",
    "    tPlus1Str=str(t+1)\n",
    "    LabBar=np.empty(l+1,dtype=object)\n",
    " \n",
    "    for i in range(1,l+2):\n",
    "        s=str(i)+\"/\"+str(l+1)\n",
    "        LabBar[i-1]=s\n",
    "    \n",
    "    if HightBar:\n",
    "        plt.ylim(0,m)\n",
    "    \n",
    "    ll=np.linspace(1-0.8,l+1+0.8,l+2)\n",
    "    \n",
    "    plt.plot(ll,np.ones(l+2),'r')\n",
    "    \n",
    "    plt.bar(x,np.ones(l+1)+VectCount,tick_label=LabBar)\n",
    "    \n",
    "    plt.title(\"Unnormalised histogram of $p_{%s}$ conditionnaly on $p_1,\\cdots,p_{%s}$\" %(tPlus1Str,tStr))\n",
    "    plt.xlabel(\"Values of $p_{%s}$\"%(tPlus1Str) )\n",
    "    plt.ylabel(\"Unnormalised probability of being equal to $x$\")\n",
    "    #plt.legend()\n",
    "    if SaveFig:\n",
    "        plt.savefig('Dynamical_'+str(t)+'.pdf',format='pdf')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphicalEvolution(l,m,ConstantGraph=False,SaveFig=False):\n",
    "    VectCount=np.zeros(l+1)\n",
    "    \n",
    "    if ConstantGraph:\n",
    "        plt.ylim(0,m+1)\n",
    "        \n",
    "    x=np.arange(1,l+2)\n",
    "    ll=np.linspace(1-0.8,l+1+0.8,l+2)\n",
    "    \n",
    "    LabBar=np.empty(l+1,dtype=object)\n",
    " \n",
    "    for i in range(1,l+2):\n",
    "        s=str(i)+\"/\"+str(l+1)\n",
    "        LabBar[i-1]=s\n",
    "    \n",
    "    if ConstantGraph:\n",
    "        plt.ylim(0,m)\n",
    "    \n",
    "    plt.bar(x,np.ones(l+1)+VectCount,tick_label=LabBar)\n",
    "    plt.plot(ll,np.ones(l+2),'r')\n",
    "    plt.title(r\"Unnormalised histogram of $p_1$\")\n",
    "    plt.xlabel(r\"Values of $p_1$\" )\n",
    "    plt.ylabel(\"Unnormalised probability of being equal to $x$\")\n",
    "    #plt.legend(bbox_to_anchor=(1.05, 1.0),loc='upper left')\n",
    "    \n",
    "    \n",
    "    \n",
    "    if SaveFig:\n",
    "        plt.savefig('Dynamical_0.pdf',format='pdf')\n",
    "    \n",
    "    #plt.legend()\n",
    "    plt.show()\n",
    "    for i in range(1,m):\n",
    "        (VectCount,P)=UpdatingPValues(l,VectCount)\n",
    "        GraphicalRepresentation(l,VectCount,ConstantGraph,m,SaveFig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "m=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26e0f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GraphicalEvolution(n,m,ConstantGraph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b2d27",
   "metadata": {},
   "source": [
    "# Some generalist code for Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba104e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The residual Score Function\n",
    "\n",
    "def my_score(y_pred, y):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the residual in order to compute the score\n",
    "    \n",
    "    y_pred: a predicted value of y by any method\n",
    "    y: the true value of y (for calibration scores) or the possible value y (for the test scores.)\n",
    "    \n",
    "    Return: the residual of y and y_pred\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.abs(y_pred - y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e10d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the \"conformal\" distribution of the calibration set in \n",
    "\n",
    "def ConformalDistrib(y_pred_cal,y_cal,n_cal,my_score):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    residuals_cal = my_score(y_pred_cal,y_cal) \n",
    "    residuals_calPlusInfini=np.append(residuals_cal,np.inf)\n",
    "\n",
    "    Residual_Distrib=stat.rv_discrete(values=np.array([residuals_calPlusInfini,np.ones(n_cal+1)/(n_cal+1)]))\n",
    "    \n",
    "    return Residual_Distrib\n",
    "\n",
    "\n",
    "def ClassicalSCP(y_pred_test,Residual_Distrib,Level):\n",
    "    quantile_scp = Residual_Distrib.ppf(1-Level)\n",
    "    ConformalIntervalUp=y_pred_test+quantile_scp\n",
    "    ConformalIntervalDown=y_pred_test-quantile_scp\n",
    "    \n",
    "    return (ConformalIntervalUp,ConformalIntervalDown,quantile_scp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f290fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NbCoverage(y_test,ConformalIntervalUp,ConformalIntervalDown):\n",
    "    return np.sum(((ConformalIntervalDown<=y_test)*(y_test<=ConformalIntervalUp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26960f",
   "metadata": {},
   "source": [
    "# The new DKW Inequality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e63ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nIter=8\n",
    "\n",
    "def IterLambda_Tau(n,m,nIter=8):\n",
    "    def lambDKW(delta):\n",
    "        lamb=1\n",
    "        \n",
    "        t_nm=n*m/(n+m)\n",
    "        A1=np.log(1/delta)\n",
    "        \n",
    "        #A2=np.sqrt(2*np.pi*(n+m))\n",
    "        \n",
    "        A2=np.sqrt(2*np.pi)*2*t_nm/np.sqrt(n+m)\n",
    "        \n",
    "        i=-1\n",
    "        while i<nIter:\n",
    "            i+=1\n",
    "            Num=A1+np.log(1+A2*(lamb))\n",
    "            lamb=np.minimum(np.sqrt(Num/(2*t_nm)),1)\n",
    "        \n",
    "        return lamb\n",
    "    return lambDKW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd100c17",
   "metadata": {},
   "source": [
    "# Transfer Learning: Code for the comparison of the Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720de7d9",
   "metadata": {},
   "source": [
    "## Creating Prediction Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a059684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Regression function\n",
    "\n",
    "def fNotNoise(x):\n",
    "    return np.cos(x)\n",
    "\n",
    "def fAndNoise(x,sigma=0.1):\n",
    "    n=len(x)\n",
    "    return fNotNoise(x)+sigma*stat.norm.rvs(size=n)\n",
    "\n",
    "# Definig the transfer function for calibration and test samples\n",
    "\n",
    "def Psi(x):\n",
    "    return 0.6*x+x**(2)/25\n",
    "\n",
    "# Defining how to simulate the Training sample and the root of the calibration and test sample\n",
    "\n",
    "def RVS_TrainSample(n,scale=5):\n",
    "    return stat.uniform.rvs(loc=0,scale=scale,size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ae5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "def ComparisonTransductiveMethods(Level,n_train,n_cal,n_test,fAndNoise,Psi,Representation=True,\n",
    "                                   RepresentationNoTransfer=True,RepresentationDiv=True,Visualisation=True,scale=5,sigma=0.1,gamma=1,\n",
    "                                   TrueRegressor=False,fNotNoise=  lambda x : 0,VisualisationSet=False,SaveFig=False):\n",
    "\n",
    "    fs=16\n",
    "    ep=3.5\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train=RVS_TrainSample(n_train,scale=5)\n",
    "    y_train=fAndNoise(X_train,sigma)\n",
    "\n",
    "    \n",
    "    X_cal1=RVS_TrainSample(n_cal,scale=5)\n",
    "    X_cal=Psi(X_cal1)\n",
    "    y_cal=fAndNoise(X_cal1,sigma)\n",
    "\n",
    "    X_test1=RVS_TrainSample(n_test,scale=5)\n",
    "    X_test=Psi(X_test1)\n",
    "    y_test=fAndNoise(X_test1,sigma)\n",
    "\n",
    "    \n",
    "    \n",
    "    if Visualisation:\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.rc('text.latex', preamble=r'\\usepackage{bm}')\n",
    "        \n",
    "        plt.scatter(X_train,y_train,marker='.',color=color_train,label=r\"$\\mathcal{D}_{{ \\mbox{train}}}$ (labeled)\",alpha=0.4)\n",
    "        plt.scatter(X_cal,y_cal,marker='o',color=color_cal,label=r\"$\\mathcal{D}_{{ \\mbox{cal}}}$ (labeled)\")\n",
    "    \n",
    "        plt.scatter(X_test,y_test,marker='*',color=color_test,zorder=2, s=50,label=r\"$\\mathcal{D}_{{ \\mbox{test}}}$ (Unlabeled)\")\n",
    "\n",
    "        plt.legend(loc=(1.04, 0.25))\n",
    "        plt.xlabel(r'$X$')\n",
    "        plt.ylabel(r'$Y$')\n",
    "        plt.show()\n",
    "\n",
    "    x_min=min(np.min(X_cal),np.min(X_test))\n",
    "    x_max=max(np.max(X_cal),np.max(X_test))\n",
    "    aux=np.linspace(x_min,x_max,10**3)\n",
    "    auxTriche=aux[np.newaxis].T\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_trainTriche=X_train[np.newaxis].T\n",
    "    X_testTriche=X_test[np.newaxis].T\n",
    "    X_calTriche=X_cal[np.newaxis].T\n",
    "    X_Label2=np.concatenate((X_cal,X_test))[np.newaxis].T\n",
    "    y_trainTriche=y_train[np.newaxis].T\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Transfer learning\n",
    "    model,loss=jdot_krr(X_trainTriche,y_trainTriche,X_Label2,gamma_g=gamma,numIterBCD = 10,ktype='rbf')\n",
    "    K_Label2=sklearn.metrics.pairwise.rbf_kernel(X_Label2,X_Label2,gamma=gamma)\n",
    "    y_pred_Label2=model.predict(K_Label2)\n",
    "    K_cal=sklearn.metrics.pairwise.rbf_kernel(X_calTriche,X_Label2,gamma=gamma)\n",
    "    y_pred_cal=model.predict(K_cal).T[0]\n",
    "    Residual_Distrib=ConformalDistrib(y_pred_cal,y_cal,n_cal,my_score)\n",
    "    K_test=sklearn.metrics.pairwise.rbf_kernel(X_testTriche,X_Label2,gamma=gamma)\n",
    "    \n",
    "    y_pred_test=model.predict(K_test).T[0]    \n",
    "    CI_OptUp,CI_OptDown,q_classical=ClassicalSCP(y_pred_test,Residual_Distrib,Level)\n",
    "    \n",
    "    print(\"Length of the prediction interval with transfer learning:\", 2*q_classical)\n",
    "    \n",
    "    ## Without Transfer Learning\n",
    "    \n",
    "    \n",
    "    modelNoTransfer,loss=jdot_krr(X_trainTriche,y_trainTriche,X_trainTriche,gamma_g=gamma,numIterBCD = 10,ktype='rbf')\n",
    "    K_testNoTransfer=sklearn.metrics.pairwise.rbf_kernel(X_testTriche,X_trainTriche,gamma=gamma)\n",
    "    y_pred_testNoTransfer=modelNoTransfer.predict(K_testNoTransfer).T[0]\n",
    "\n",
    "    K_calNoTransfer=sklearn.metrics.pairwise.rbf_kernel(X_calTriche,X_trainTriche,gamma=gamma)\n",
    "    y_pred_calNoTransfer=modelNoTransfer.predict(K_calNoTransfer).T[0]\n",
    "\n",
    "    Residual_DistribNoTransfer=ConformalDistrib(y_pred_calNoTransfer,y_cal,n_cal,my_score)\n",
    "    CI_OptUpNoTransfer,CI_OptDownNoTransfer,q_classicalNoTransfer=ClassicalSCP(y_pred_testNoTransfer,Residual_DistribNoTransfer,Level)\n",
    "    \n",
    "    print(\"Length of the prediction interval without transfer learning:\", 2*q_classicalNoTransfer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##Without Transfer Learning with D_cal Split\n",
    "    \n",
    "\n",
    "    n_cal_train=int(np.ceil(n_cal/2))\n",
    "    n_cal_cal=n_cal-n_cal_train\n",
    "    X_cal_train=X_cal[:n_cal_train]\n",
    "    y_cal_train=y_cal[:n_cal_train]\n",
    "    X_cal_cal=X_cal[n_cal_train:]\n",
    "    y_cal_cal=y_cal[n_cal_train:]\n",
    "\n",
    "    X_cal_trainTriche=X_cal_train[np.newaxis].T\n",
    "    X_cal_calTriche=X_cal_cal[np.newaxis].T\n",
    "\n",
    "    y_cal_trainTriche=y_cal_train[np.newaxis].T\n",
    "\n",
    "    X_Label2Div=np.concatenate((X_cal_cal,X_test))\n",
    "    X_Label2DivTriche=X_Label2Div[np.newaxis].T\n",
    "    y_label2Div=np.concatenate((y_cal_cal,y_test))\n",
    "    y_label2DivTriche=y_label2Div[np.newaxis].T\n",
    "\n",
    "\n",
    "    modelDiv,loss=jdot_krr(X_cal_trainTriche,y_cal_trainTriche,X_cal_trainTriche,gamma_g=gamma,numIterBCD = 10,ktype='rbf')\n",
    "\n",
    "    K_cal_cal=sklearn.metrics.pairwise.rbf_kernel(X_cal_calTriche,X_cal_trainTriche,gamma=gamma)\n",
    "    K_testDiv=sklearn.metrics.pairwise.rbf_kernel(X_testTriche,X_cal_trainTriche,gamma=gamma)\n",
    "\n",
    "    y_pred_testDiv=modelDiv.predict(K_testDiv).T[0]\n",
    "    y_pred_cal_cal=modelDiv.predict(K_cal_cal).T[0]\n",
    "\n",
    "\n",
    "\n",
    "    Residual_DistribDiv=ConformalDistrib(y_pred_cal_cal,y_cal_cal,n_cal_cal,my_score)\n",
    "    CI_OptUpDiv,CI_OptDownDiv,q_classicalDiv=ClassicalSCP(y_pred_testDiv,Residual_DistribDiv,Level)\n",
    "\n",
    "    print(\"Length of the prediction interval without transfer learning and by splitting D_cal:\", 2*q_classicalDiv)\n",
    "    \n",
    "    \n",
    "    nTab=np.array([n_cal,n_cal,n_cal_cal])\n",
    "    mTab=np.array([n_test,n_test,n_test])\n",
    "    y_predTab=np.array([y_pred_test,y_pred_testNoTransfer,y_pred_testDiv])\n",
    "    \n",
    "    ## Graphical representation of prediction intervall\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.rc('text.latex', preamble=r'\\usepackage{bm}')\n",
    "        \n",
    "        \n",
    "    for tickLabel in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "        tickLabel.set_fontsize(fs)    \n",
    "    \n",
    "    if TrueRegressor:\n",
    "        auxBis=np.linspace(0,scale,10**4)\n",
    "        auxBisGraph=Psi(auxBis)\n",
    "        Regressor=fNotNoise(auxBis)\n",
    "        plt.plot(auxBisGraph,Regressor,'-',color='k',label=r\"True regression function\",linewidth=ep)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if Representation:\n",
    "        K_aux=sklearn.metrics.pairwise.rbf_kernel(auxTriche,X_Label2,gamma=gamma)\n",
    "        y_pred_aux=model.predict(K_aux).T[0]\n",
    "        CI_OptUpaux,CI_OptDownaux,q_classical=ClassicalSCP(y_pred_aux,Residual_Distrib,Level)\n",
    "\n",
    "        plt.plot(aux,CI_OptUpaux,':',color=colors_blindness[1],label=r'$\\bm{\\mathcal{I}}^{ \\mbox{transfer}}$ (This work)',linewidth=ep)\n",
    "        plt.plot(aux,CI_OptDownaux,':',color=colors_blindness[1],linewidth=ep)\n",
    "\n",
    "    \n",
    "    if RepresentationNoTransfer:\n",
    "        \n",
    "        K_auxNoTransfer=sklearn.metrics.pairwise.rbf_kernel(auxTriche,X_trainTriche,gamma=gamma)\n",
    "        y_pred_auxNoTransfer=modelNoTransfer.predict(K_auxNoTransfer).T[0]\n",
    "\n",
    "        CI_OptUpauxNoTransfer,CI_OptDownauxNoTransfer, q=ClassicalSCP(y_pred_auxNoTransfer,Residual_DistribNoTransfer,Level)\n",
    "\n",
    "        plt.plot(aux,CI_OptUpauxNoTransfer,':',color=colors_blindness[2],label=r'$\\bm{\\mathcal{I}}^{\\mbox{naive}}$',linewidth=ep)\n",
    "        plt.plot(aux,CI_OptDownauxNoTransfer,':',color=colors_blindness[2],linewidth=ep)\n",
    "    \n",
    "    if RepresentationDiv:\n",
    "        \n",
    "        K_auxDiv=sklearn.metrics.pairwise.rbf_kernel(auxTriche,X_cal_trainTriche,gamma=gamma)\n",
    "        y_pred_auxDiv=modelDiv.predict(K_auxDiv).T[0]\n",
    "        CI_OptUpauxDiv,CI_OptDownauxDiv,q_classicalDiv=ClassicalSCP(y_pred_auxDiv,Residual_DistribDiv,Level)\n",
    "        \n",
    "        plt.plot(aux,CI_OptUpauxDiv,':',color=colors_blindness[0],label=r'$\\bm{\\mathcal{I}}^{ \\mbox{split}}$',linewidth=ep)\n",
    "        plt.plot(aux,CI_OptDownauxDiv,':',color=colors_blindness[0],linewidth=ep)\n",
    "\n",
    "        \n",
    "    if VisualisationSet:\n",
    "        plt.scatter(X_train,y_train,marker='.',color=color_train,label=r\"$\\mathcal{D}_{{ \\mbox{train}}}$ (Labeled)\",alpha=0.4)\n",
    "        plt.scatter(X_cal,y_cal,marker='o',color=color_cal,label=r\"$\\mathcal{D}_{{ \\mbox{cal}}}$ (Labeled)\")\n",
    "    \n",
    "    plt.scatter(X_test,y_test,marker='*',color=color_test,zorder=2, s=50,label=r\"$\\mathcal{D}_{{ \\mbox{test}}}$ (Unlabeled)\")\n",
    "    plt.legend(loc='upper right', fontsize=fs)\n",
    "    plt.xlabel('x',fontsize=fs)\n",
    "    plt.ylabel('y',fontsize=fs)\n",
    "    if SaveFig:\n",
    "        plt.savefig('TransferCP_'+str(n_train)+'_'+str(n_cal)+'_'+str(n_test)+'.pdf',format='pdf')\n",
    "    \n",
    "    plt.show()\n",
    "    return(np.array([Residual_Distrib,Residual_DistribNoTransfer,Residual_DistribDiv]),nTab,mTab,y_test,y_predTab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Level=0.1\n",
    "n_train=1000\n",
    "n_cal=30\n",
    "n_test=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ffa1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ComparisonTransductiveMethods(Level,n_train,n_cal,n_test,fAndNoise,Psi,Representation=True,\n",
    "                                   RepresentationNoTransfer=True,RepresentationDiv=True,Visualisation=True,scale=5,sigma=0.1,gamma=1,\n",
    "                                   TrueRegressor=True,fNotNoise=fNotNoise,VisualisationSet=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComparisonTransductiveMethodsBlackandWhite(Level,n_train,n_cal,n_test,fAndNoise,Psi,Representation=True,\n",
    "                                   RepresentationNoTransfer=True,RepresentationDiv=True,Visualisation=True,scale=5,sigma=0.1,gamma=1,\n",
    "                                   TrueRegressor=False,fNotNoise=  lambda x : 0,VisualisationSet=False,SaveFig=False):\n",
    "\n",
    "    fs=16\n",
    "    ep=3.5\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train=RVS_TrainSample(n_train,scale=5)\n",
    "    y_train=fAndNoise(X_train,sigma)\n",
    "\n",
    "    \n",
    "    X_cal1=RVS_TrainSample(n_cal,scale=5)\n",
    "    X_cal=Psi(X_cal1)\n",
    "    y_cal=fAndNoise(X_cal1,sigma)\n",
    "\n",
    "    X_test1=RVS_TrainSample(n_test,scale=5)\n",
    "    X_test=Psi(X_test1)\n",
    "    y_test=fAndNoise(X_test1,sigma)\n",
    "\n",
    "    \n",
    "    \n",
    "    if Visualisation:\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.rc('text.latex', preamble=r'\\usepackage{bm}')\n",
    "        \n",
    "        plt.scatter(X_train,y_train,marker='.',color=color_train,label=r\"$\\mathcal{D}_{{ \\mbox{train}}}$ (labeled)\",alpha=0.4)\n",
    "        plt.scatter(X_cal,y_cal,marker='o',color=color_cal,label=r\"$\\mathcal{D}_{{ \\mbox{cal}}}$ (labeled)\")\n",
    "    \n",
    "        plt.scatter(X_test,y_test,marker='*',color=color_test,zorder=2, s=50,label=r\"$\\mathcal{D}_{{ \\mbox{test}}}$ (Unlabeled)\")\n",
    "\n",
    "        plt.legend(loc=(1.04, 0.25))\n",
    "        plt.xlabel(r'$X$')\n",
    "        plt.ylabel(r'$Y$')\n",
    "        plt.show()\n",
    "\n",
    "    x_min=min(np.min(X_cal),np.min(X_test))\n",
    "    x_max=max(np.max(X_cal),np.max(X_test))\n",
    "    aux=np.linspace(x_min,x_max,10**3)\n",
    "    auxTriche=aux[np.newaxis].T\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_trainTriche=X_train[np.newaxis].T\n",
    "    X_testTriche=X_test[np.newaxis].T\n",
    "    X_calTriche=X_cal[np.newaxis].T\n",
    "    X_Label2=np.concatenate((X_cal,X_test))[np.newaxis].T\n",
    "    y_trainTriche=y_train[np.newaxis].T\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Transfer learning\n",
    "    model,loss=jdot_krr(X_trainTriche,y_trainTriche,X_Label2,gamma_g=gamma,numIterBCD = 10,ktype='rbf')\n",
    "    K_Label2=sklearn.metrics.pairwise.rbf_kernel(X_Label2,X_Label2,gamma=gamma)\n",
    "    y_pred_Label2=model.predict(K_Label2)\n",
    "    K_cal=sklearn.metrics.pairwise.rbf_kernel(X_calTriche,X_Label2,gamma=gamma)\n",
    "    y_pred_cal=model.predict(K_cal).T[0]\n",
    "    Residual_Distrib=ConformalDistrib(y_pred_cal,y_cal,n_cal,my_score)\n",
    "    K_test=sklearn.metrics.pairwise.rbf_kernel(X_testTriche,X_Label2,gamma=gamma)\n",
    "    \n",
    "    y_pred_test=model.predict(K_test).T[0]    \n",
    "    CI_OptUp,CI_OptDown,q_classical=ClassicalSCP(y_pred_test,Residual_Distrib,Level)\n",
    "    \n",
    "    print(\"Length of the prediction interval with Transfer learning:\", 2*q_classical)\n",
    "    \n",
    "    ## Without Transfer Learning\n",
    "    \n",
    "    \n",
    "    modelNoTransfer,loss=jdot_krr(X_trainTriche,y_trainTriche,X_trainTriche,gamma_g=gamma,numIterBCD = 10,ktype='rbf')\n",
    "    K_testNoTransfer=sklearn.metrics.pairwise.rbf_kernel(X_testTriche,X_trainTriche,gamma=gamma)\n",
    "    y_pred_testNoTransfer=modelNoTransfer.predict(K_testNoTransfer).T[0]\n",
    "\n",
    "    K_calNoTransfer=sklearn.metrics.pairwise.rbf_kernel(X_calTriche,X_trainTriche,gamma=gamma)\n",
    "    y_pred_calNoTransfer=modelNoTransfer.predict(K_calNoTransfer).T[0]\n",
    "\n",
    "    Residual_DistribNoTransfer=ConformalDistrib(y_pred_calNoTransfer,y_cal,n_cal,my_score)\n",
    "    CI_OptUpNoTransfer,CI_OptDownNoTransfer,q_classicalNoTransfer=ClassicalSCP(y_pred_testNoTransfer,Residual_DistribNoTransfer,Level)\n",
    "    \n",
    "    print(\"Length of the prediction interval without Transfer learning:\", 2*q_classicalNoTransfer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##Without Transfer Learning with D_cal Split\n",
    "    \n",
    "\n",
    "    n_cal_train=int(np.ceil(n_cal/2))\n",
    "    n_cal_cal=n_cal-n_cal_train\n",
    "    X_cal_train=X_cal[:n_cal_train]\n",
    "    y_cal_train=y_cal[:n_cal_train]\n",
    "    X_cal_cal=X_cal[n_cal_train:]\n",
    "    y_cal_cal=y_cal[n_cal_train:]\n",
    "\n",
    "    X_cal_trainTriche=X_cal_train[np.newaxis].T\n",
    "    X_cal_calTriche=X_cal_cal[np.newaxis].T\n",
    "\n",
    "    y_cal_trainTriche=y_cal_train[np.newaxis].T\n",
    "\n",
    "    X_Label2Div=np.concatenate((X_cal_cal,X_test))\n",
    "    X_Label2DivTriche=X_Label2Div[np.newaxis].T\n",
    "    y_label2Div=np.concatenate((y_cal_cal,y_test))\n",
    "    y_label2DivTriche=y_label2Div[np.newaxis].T\n",
    "\n",
    "\n",
    "    modelDiv,loss=jdot_krr(X_cal_trainTriche,y_cal_trainTriche,X_cal_trainTriche,gamma_g=gamma,numIterBCD = 10,ktype='rbf')\n",
    "\n",
    "    K_cal_cal=sklearn.metrics.pairwise.rbf_kernel(X_cal_calTriche,X_cal_trainTriche,gamma=gamma)\n",
    "    K_testDiv=sklearn.metrics.pairwise.rbf_kernel(X_testTriche,X_cal_trainTriche,gamma=gamma)\n",
    "\n",
    "    y_pred_testDiv=modelDiv.predict(K_testDiv).T[0]\n",
    "    y_pred_cal_cal=modelDiv.predict(K_cal_cal).T[0]\n",
    "\n",
    "\n",
    "\n",
    "    Residual_DistribDiv=ConformalDistrib(y_pred_cal_cal,y_cal_cal,n_cal_cal,my_score)\n",
    "    CI_OptUpDiv,CI_OptDownDiv,q_classicalDiv=ClassicalSCP(y_pred_testDiv,Residual_DistribDiv,Level)\n",
    "\n",
    "    print(\"Length of the prediction interval without Transfer learning and by splitting D_cal:\", 2*q_classicalDiv)\n",
    "    \n",
    "    \n",
    "    nTab=np.array([n_cal,n_cal,n_cal_cal])\n",
    "    mTab=np.array([n_test,n_test,n_test])\n",
    "    y_predTab=np.array([y_pred_test,y_pred_testNoTransfer,y_pred_testDiv])\n",
    "    \n",
    "    ## Graphical representation of prediction intervall\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.rc('text.latex', preamble=r'\\usepackage{bm}')\n",
    "        \n",
    "        \n",
    "    for tickLabel in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "        tickLabel.set_fontsize(fs)    \n",
    "    \n",
    "    if TrueRegressor:\n",
    "        auxBis=np.linspace(0,scale,10**4)\n",
    "        auxBisGraph=Psi(auxBis)\n",
    "        Regressor=fNotNoise(auxBis)\n",
    "        plt.plot(auxBisGraph,Regressor,'-',color='k',label=r\"True regression function\",linewidth=ep)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if Representation:\n",
    "        K_aux=sklearn.metrics.pairwise.rbf_kernel(auxTriche,X_Label2,gamma=gamma)\n",
    "        y_pred_aux=model.predict(K_aux).T[0]\n",
    "        CI_OptUpaux,CI_OptDownaux,q_classical=ClassicalSCP(y_pred_aux,Residual_Distrib,Level)\n",
    "\n",
    "        plt.plot(aux,CI_OptUpaux,'.-',color=colors_blindness[1],label=r'$\\bm{\\mathcal{I}}^{ \\mbox{transfer}}$ (This work)',linewidth=ep)\n",
    "        plt.plot(aux,CI_OptDownaux,'.-',color=colors_blindness[1],linewidth=ep)\n",
    "\n",
    "    \n",
    "    if RepresentationNoTransfer:\n",
    "        \n",
    "        K_auxNoTransfer=sklearn.metrics.pairwise.rbf_kernel(auxTriche,X_trainTriche,gamma=gamma)\n",
    "        y_pred_auxNoTransfer=modelNoTransfer.predict(K_auxNoTransfer).T[0]\n",
    "\n",
    "        CI_OptUpauxNoTransfer,CI_OptDownauxNoTransfer, q=ClassicalSCP(y_pred_auxNoTransfer,Residual_DistribNoTransfer,Level)\n",
    "\n",
    "        plt.plot(aux,CI_OptUpauxNoTransfer,':',color=colors_blindness[2],label=r'$\\bm{\\mathcal{I}}^{\\mbox{naive}}$',linewidth=ep)\n",
    "        plt.plot(aux,CI_OptDownauxNoTransfer,':',color=colors_blindness[2],linewidth=ep)\n",
    "    \n",
    "    if RepresentationDiv:\n",
    "        \n",
    "        K_auxDiv=sklearn.metrics.pairwise.rbf_kernel(auxTriche,X_cal_trainTriche,gamma=gamma)\n",
    "        y_pred_auxDiv=modelDiv.predict(K_auxDiv).T[0]\n",
    "        CI_OptUpauxDiv,CI_OptDownauxDiv,q_classicalDiv=ClassicalSCP(y_pred_auxDiv,Residual_DistribDiv,Level)\n",
    "        \n",
    "        plt.plot(aux,CI_OptUpauxDiv,'--',color=colors_blindness[0],label=r'$\\bm{\\mathcal{I}}^{ \\mbox{split}}$',linewidth=ep)\n",
    "        plt.plot(aux,CI_OptDownauxDiv,'--',color=colors_blindness[0],linewidth=ep)\n",
    "\n",
    "        \n",
    "    if VisualisationSet:\n",
    "        plt.scatter(X_train,y_train,marker='.',color=color_train,label=r\"$\\mathcal{D}_{{ \\mbox{train}}}$ (Labeled)\",alpha=0.4)\n",
    "        plt.scatter(X_cal,y_cal,marker='o',color=color_cal,label=r\"$\\mathcal{D}_{{ \\mbox{cal}}}$ (Labeled)\")\n",
    "    \n",
    "    plt.scatter(X_test,y_test,marker='*',color=color_test,zorder=2, s=50,label=r\"$\\mathcal{D}_{{ \\mbox{test}}}$ (Unlabeled)\")\n",
    "    plt.legend(loc='upper right', fontsize=fs)\n",
    "    plt.xlabel('x',fontsize=fs)\n",
    "    plt.ylabel('y',fontsize=fs)\n",
    "    if SaveFig:\n",
    "        plt.savefig('TransferCP_'+str(n_train)+'_'+str(n_cal)+'_'+str(n_test)+'.pdf',format='pdf')\n",
    "    \n",
    "    plt.show()\n",
    "    return(np.array([Residual_Distrib,Residual_DistribNoTransfer,Residual_DistribDiv]),nTab,mTab,y_test,y_predTab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e74d86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ComparisonTransductiveMethodsBlackandWhite(Level,n_train,n_cal,n_test,fAndNoise,Psi,Representation=True,\n",
    "                                   RepresentationNoTransfer=True,RepresentationDiv=True,Visualisation=True,scale=5,sigma=0.1,gamma=1,\n",
    "                                   TrueRegressor=True,fNotNoise=fNotNoise,VisualisationSet=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eda4b7",
   "metadata": {},
   "source": [
    "# Post Hoc bounds for Prediction Interval Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3683a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MajSimes(n,m,alpha,delta):\n",
    "    return np.minimum(np.ceil(m*delta/alpha)-1,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MajDKWConv(n,m,delta,alpha):\n",
    "    lamb=IterLambda_Tau(n,m,nIter)(delta)\n",
    "    I_n_alpha=np.floor((n+1)*alpha)/(n+1)\n",
    "\n",
    "    return np.minimum(np.ceil(m*(I_n_alpha+lamb))-1,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlphaChap(L,n,m,Distrib_Residual):\n",
    "    T=1-Distrib_Residual.cdf(L/2)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MajPropErrorBoundsAlphaChapComparison(n,m,L,delta,y_pred_test=np.ones(shape=(1,1)),y_test=np.ones(1),Distrib_Residual=np.array([stat.uniform])):\n",
    "    \n",
    "    L=np.sort(L)\n",
    "    l=len(L)\n",
    "    r=len(Distrib_Residual)\n",
    "    Alpha_L=np.zeros(shape=(r,l))\n",
    "    PropMajDKWConv=np.zeros(shape=(r,l))\n",
    "    print(np.shape(PropMajDKWConv))\n",
    "    PropMajSimes=np.zeros(shape=(r,l))\n",
    "    for i in range (r):\n",
    "        Alpha_L[i]=AlphaChap(L,n[i],m[i],Distrib_Residual[i])\n",
    "    #print(Alpha_L)\n",
    "        PropMajSimes[i]=MajSimes(n[i],m[i],delta,Alpha_L[i])/m[i]\n",
    "    #print(PropMajSimes)\n",
    "        PropMajDKWConv[i]=MajDKWConv(n[i],m[i],delta,Alpha_L[i])/m[i]\n",
    "    #print(PropMajDKWConv)\n",
    "    \n",
    "\n",
    "    PropErrror=np.ones(shape=(r,l))\n",
    "    for j in range (r) :\n",
    "        for i in range (l):\n",
    "            Level=Alpha_L[j,i]\n",
    "            (CIClassical_Up,CIClassical_Down,q_classical)=ClassicalSCP(y_pred_test[j],Distrib_Residual[j],Level)\n",
    "            PropErrror[j,i]=1-NbCoverage(y_test,CIClassical_Up,CIClassical_Down)/m[j]\n",
    "\n",
    "    print(np.shape(PropErrror))\n",
    "    print(np.shape(PropMajDKWConv))\n",
    "    return(PropMajDKWConv,PropMajSimes,PropErrror,Alpha_L)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphTransferPostHoc(L,PropMajDKWConv,PropMajSimes,PropError,Alpha_L,delta,n_train=0,n_cal=0,n_test=0,SaveFig=False):\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.rc('text.latex', preamble=r'\\usepackage{bm} ')\n",
    "    ep=2.5\n",
    "    fs=16\n",
    "    for tickLabel in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "        tickLabel.set_fontsize(fs)\n",
    "    \n",
    "    \n",
    "    plt.plot(L,PropError[0],':',color=colors_blindness[1],label=r\"$\\mathrm{FCP}\\Big(\\bm{\\mathcal{I}}^{ \\mbox{transfer}}\\Big)$\",linewidth=ep)\n",
    "    plt.plot(L,PropMajDKWConv[0], color=colors_blindness[1],label=r\"${\\overline{\\mathrm{FCP}}}_\\delta^{\\small\\mbox{ DKW}}\\Big(\\bm{\\mathcal{I}}^{ \\mbox{transfer}}\\Big)$\",linewidth=ep)\n",
    "    \n",
    "    plt.plot(L,PropError[1],':',color=colors_blindness[2],label=r\"$\\mathrm{FCP}\\Big(\\bm{\\mathcal{I}}^{ \\mbox{naive}}\\Big)$\",linewidth=ep)\n",
    "    plt.plot(L,PropMajDKWConv[1], color=colors_blindness[2],label=r\"${\\overline{\\mathrm{FCP}}}_\\delta^{\\small\\mbox{ DKW}}\\Big(\\bm{\\mathcal{I}}^{ \\mbox{naive}}\\Big)$\",linewidth=ep)\n",
    "    \n",
    "    plt.plot(L,PropError[2],':',color=colors_blindness[0],label=r\"$\\mathrm{FCP}\\Big(\\bm{\\mathcal{I}}^{ \\mbox{split}}\\Big)$\",linewidth=ep)\n",
    "    plt.plot(L,PropMajDKWConv[2],color=colors_blindness[0],label=r\"${\\overline{\\mathrm{FCP}}}_\\delta^{\\small\\mbox{ DKW}}\\Big(\\bm{\\mathcal{I}}^{ \\mbox{split}}\\Big)$\",linewidth=ep)\n",
    "    \n",
    "    deltaString=str(delta)\n",
    "    plt.xlabel(r\"Prediction Interval length $2L$\", fontsize=fs)\n",
    "    plt.ylabel(\"Error proportion\", fontsize=fs)\n",
    "    plt.legend(loc='upper right', fontsize=fs)\n",
    "    if SaveFig:\n",
    "        plt.savefig('Alpha_L_Comparison_'+str(n_train)+'_'+str(n_cal)+'_'+str(n_test)+'.pdf',format='pdf')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de16d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransferPostHoc(L,Level,n_train,n_cal,n_test,fAndNoise,Psi,Representation=False,RepresentationNoTransfer=False,RepresentationDiv=False,Visualisation=False,scale=5,sigma=0.1,gamma=1,TrueRegressor=False,fNotNoise=  lambda x : 0,VisualisationSet=True,BlackandWhite=False,SaveFig=False):\n",
    "\n",
    "\n",
    "\n",
    "    if BlackandWhite:\n",
    "        Distrib,nTab,mTab,y_test,y_predTab=ComparisonTransductiveMethodsBlackandWhite(Level,n_train,n_cal,n_test,fAndNoise,Psi,Representation,RepresentationNoTransfer,RepresentationDiv,Visualisation,scale,sigma,gamma,TrueRegressor,fNotNoise,VisualisationSet,SaveFig)\n",
    "    else:\n",
    "        Distrib,nTab,mTab,y_test,y_predTab=ComparisonTransductiveMethods(Level,n_train,n_cal,n_test,fAndNoise,Psi,Representation,RepresentationNoTransfer,RepresentationDiv,Visualisation,scale,sigma,gamma,TrueRegressor,fNotNoise,VisualisationSet,SaveFig)\n",
    "    PropMajDKWConv,PropMajSimes,PropError,Alpha_L=MajPropErrorBoundsAlphaChapComparison(nTab,mTab,L,delta,y_predTab,y_test,Distrib)\n",
    "    \n",
    "    GraphTransferPostHoc(L,PropMajDKWConv,PropMajSimes,PropError,Alpha_L,delta,n_train,n_cal,n_test,SaveFig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ed7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "L=np.linspace(0.001,2,10**3)\n",
    "delta=0.2\n",
    "n_train=1000\n",
    "n_cal=30\n",
    "n_test=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6bd63c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TransferPostHoc(L,Level,n_train,n_cal,n_test,fAndNoise,Psi,Representation=True,RepresentationNoTransfer=True,RepresentationDiv=True,Visualisation=True,TrueRegressor=True,fNotNoise= fNotNoise,VisualisationSet=True,BlackandWhite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c88e8",
   "metadata": {},
   "source": [
    "## With Other Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abee90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Regression function\n",
    "\n",
    "#Heteroscedasticity\n",
    "\n",
    "\n",
    "\n",
    "def fAndNoiseHetero(x,sigma=0.1):\n",
    "    n=len(x)\n",
    "    return fNotNoise(x)+sigma*(np.cos(x))*stat.norm.rvs(size=n)\n",
    "\n",
    "# Definig the transfer function for calibration and test samples\n",
    "\n",
    "def Psi(x):\n",
    "    return 0.6*x+x**(2)/25\n",
    "\n",
    "# Defining how to simulate the Training sample and the root of the calibration and test sample\n",
    "\n",
    "def RVS_TrainSample(n,scale=5):\n",
    "    return stat.uniform.rvs(loc=0,scale=scale,size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e144079",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=1000\n",
    "n_cal=300\n",
    "n_test=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634d5d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TransferPostHoc(L,Level,n_train,n_cal,n_test,fAndNoiseHetero,Psi,Representation=True,RepresentationNoTransfer=True,RepresentationDiv=True,Visualisation=True,TrueRegressor=True,fNotNoise= fNotNoise,VisualisationSet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd4797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Regression function\n",
    "\n",
    "\n",
    "\n",
    "def fNotNoise3(x):\n",
    "    return np.cos(x)-x**2+x**3\n",
    "\n",
    "def fAndNoise3(x,sigma=0.1):\n",
    "    n=len(x)\n",
    "    return fNotNoise3(x)+sigma*stat.norm.rvs(size=n)\n",
    "\n",
    "# Defining the transfer function for calibration and test samples\n",
    "\n",
    "def Psi3(x):\n",
    "    return 0.8*np.log(x)+2*x\n",
    "\n",
    "# Defining how to simulate the Training sample and the root of the calibration and test sample\n",
    "\n",
    "def RVS_TrainSample(n,scale=5):\n",
    "    return stat.uniform.rvs(loc=0,scale=scale,size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=1000\n",
    "n_cal=300\n",
    "n_test=200\n",
    "\n",
    "L=np.linspace(0.01,20,10**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1c2469",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TransferPostHoc(L,Level,n_train,n_cal,n_test,fAndNoise3,Psi3,Representation=True,RepresentationNoTransfer=True,RepresentationDiv=True,Visualisation=True,TrueRegressor=True,fNotNoise= fNotNoise3,VisualisationSet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ea485",
   "metadata": {},
   "source": [
    "# Post Hoc bounds for Novelty Detection Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487042d8",
   "metadata": {},
   "source": [
    "## Loading Shuttle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe77934",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetShuttle = fetch_openml(name='shuttle',  as_frame=False)\n",
    "XShuttle = datasetShuttle.data\n",
    "yShuttle = datasetShuttle.target.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e67b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test sample \n",
    "outlrShuttle, inlrShuttle = XShuttle[np.minimum(yShuttle!=1,1)], XShuttle[yShuttle==1]\n",
    "m1Shuttle = 300\n",
    "m0Shuttle = 1500\n",
    "\n",
    "np.random.shuffle(inlrShuttle)\n",
    "np.random.shuffle(outlrShuttle)\n",
    "\n",
    "test1Shuttle, test0Shuttle = outlrShuttle[:m1Shuttle], inlrShuttle[:m0Shuttle]\n",
    "xShuttle = np.concatenate([test0Shuttle, test1Shuttle]) \n",
    "n_testShuttle=m1Shuttle+m0Shuttle\n",
    "print(m0Shuttle/(m1Shuttle+m0Shuttle))\n",
    "\n",
    "#NTS\n",
    "nShuttle=5000\n",
    "SplitSizeShuttle=3000/5000\n",
    "n_trainShuttle=int(SplitSizeShuttle*nShuttle)\n",
    "n_calShuttle=nShuttle-n_trainShuttle\n",
    "\n",
    "\n",
    "xnullShuttle = inlrShuttle[m0Shuttle:m0Shuttle+nShuttle]\n",
    "\n",
    "\n",
    "\n",
    "procShuttle = AdaDetectERM(scoring_fn = RandomForestClassifier(max_depth=10),\n",
    "                                 split_size=SplitSizeShuttle) \n",
    "procBatesShuttle=AdaDetectDE(scoring_fn = OCC(scoring_fn = IsolationForest(contamination=0.1)), f0_known = False,\n",
    "                            split_size=SplitSizeShuttle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e435735",
   "metadata": {},
   "source": [
    "## Compute $\\hat{m}_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41740d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m0Adaptatif(delta,pValeurs,n_cal,n_test,Show=True):\n",
    "    \n",
    "    \n",
    "    mm=np.arange(n_test)+1\n",
    "    \n",
    "    I_n=np.arange(n_cal+2)/(n_cal+1)\n",
    "    #Calcul des V_t=Sum(1{p_i>t})\n",
    "    \n",
    "    \n",
    "    V=np.zeros(n_cal+2)\n",
    "    \n",
    "    V[0]=n_test\n",
    "    V[n_cal+1]=0\n",
    "    \n",
    "    Lamb=IterLambda_Tau(n_cal,mm,nIter)(delta)\n",
    "    \n",
    "    for i in range(1,n_cal+1):\n",
    "        V[i]=np.sum(pValeurs>I_n[i])\n",
    "        \n",
    "        \n",
    "        \n",
    "    #m0 for DKW:\n",
    "    InfEst=np.zeros(n_test)\n",
    "    Max_rLambda=1*Lamb[0]*np.ones(n_test)\n",
    "    InfEst[0]=np.min((V[1:n_cal+1]+Max_rLambda[0])/(1-I_n[1:n_cal+1]))\n",
    "    \n",
    "    for r in range(2,n_test-1):\n",
    "        \n",
    "        Current_rLambda=r*Lamb[r-1]\n",
    "        if Max_rLambda[r-2]<Current_rLambda:\n",
    "            Max_rLambda[r-1]=Current_rLambda\n",
    "        InfEst[r-1]=np.min((V[1:n_cal+1]+Max_rLambda[r-1])/(1-I_n[1:n_cal+1]))\n",
    "    \n",
    "    PlusGrand=mm*(InfEst>=mm)\n",
    "    m0_Hat_DKW=np.max(PlusGrand)\n",
    "    if  m0_Hat_DKW==0:\n",
    "         m0_Hat_DKW=n_test\n",
    "    \n",
    "    DevDKWBound=Max_rLambda[m0_Hat_DKW-1]\n",
    "    \n",
    "    \n",
    "    #m0 for Simes:\n",
    "    if delta*(n_cal+1)==np.floor(delta*(n_cal+1)):\n",
    "        t_max=int(np.floor(delta*(n_cal+1)))\n",
    "    else:\n",
    "        t_max=int(np.floor(delta*(n_cal+1)))+1\n",
    "    \n",
    "    m0_Hat_Simes=min(n_test,int(np.ceil(np.min(V[1:t_max]/(1-I_n[1:t_max]/delta)))))\n",
    "    \n",
    "    if Show:\n",
    "        print('m0_Hat_DKW:' +str(m0_Hat_DKW))\n",
    "        print('m0_Hat_Simes:' +str(m0_Hat_Simes))\n",
    "    \n",
    "    return (m0_Hat_DKW,m0_Hat_Simes,V,DevDKWBound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e7bc8",
   "metadata": {},
   "source": [
    "## Post Hoc Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828d956",
   "metadata": {},
   "source": [
    "### $p$-value Threshold: t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62198b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PostHoc_Uniforme_t(delta,x,xnull,procedure,n_cal,n_test,m0,Oracle=False):\n",
    "    \n",
    "    \n",
    "    procedure.fit(x,0.5,xnull)\n",
    "    \n",
    "    n=n_cal\n",
    "    m=n_test\n",
    "    print('m1:'+str(n_test-m0))\n",
    "    print('m0:' +str(m0))\n",
    "    \n",
    "\n",
    "    FDP=np.zeros(n+2)\n",
    "    Rejet=np.zeros(n+2)\n",
    "    \n",
    "    FDP[n+1]=m0/m\n",
    "    Rejet[n+1]=m\n",
    "    \n",
    "    I_n=np.arange(n+2)/(n+1)\n",
    "    \n",
    "    \n",
    "    pValeurs=np.array([compute_pvalue(x, procedure.null_statistics) for x in procedure.test_statistics])\n",
    "    \n",
    "    \n",
    "    (m0_Hat_DKW,m0_Hat_Simes,V,DevDKWBound)=m0Adaptatif(delta,pValeurs,n_cal,n_test)\n",
    "    \n",
    "    \n",
    "    if Oracle:\n",
    "        m0_Hat_DKW,m0_Hat_Simes=m0,m0\n",
    "        DevDKWBound=IterLambda_Tau(n_cal,m0_Hat_DKW,nIter)(delta)\n",
    "    \n",
    "    #FDP Computation\n",
    "    \n",
    "    for i in range (1,n+2):\n",
    "        level=i/(n+1)\n",
    "        Rejet[i]=np.sum(pValeurs<=level)\n",
    "        FDP[i]=np.sum((pValeurs[:m0]<=level))/max(Rejet[i],1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Post Hoc Bounds\n",
    "    \n",
    "\n",
    "    \n",
    "    Maj_DKW_PostHoc=np.minimum(((m0_Hat_DKW*I_n+DevDKWBound)*(Rejet>0))/(np.maximum(Rejet,1)),1)\n",
    "     \n",
    "  \n",
    "    \n",
    "    \n",
    "    Maj_Simes_PostHoc=np.minimum(m0_Hat_Simes*I_n*(Rejet>0)/(np.maximum(Rejet,1)*delta),1)\n",
    "    \n",
    "    \n",
    "    return(FDP,Rejet,Maj_DKW_PostHoc,Maj_Simes_PostHoc,m0_Hat_DKW,m0_Hat_Simes,pValeurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c15983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComparisonUniformePostHoc(delta,x,xnull,procedure,procedureBates,n_cal,n_test,m0,m1,t_min=1,Prop_t_max=0.2, VisualisationDouble=True,Oracle=False,SaveFig=False):\n",
    "    \n",
    "    FDP,Rejet,Maj_DKW_PostHoc,Maj_Simes_PostHoc,m0_Hat_DKW,m0_Hat_Simes,pValeurs=PostHoc_Uniforme_t(delta,x,xnull,procedure,n_cal,n_test,m0,Oracle=Oracle)\n",
    "    FDPBates,RejetBates,Maj_DKW_PostHocBates,Maj_Simes_PostHocBates,m0_Hat_DKWBates,m0_Hat_SimesBates,pValeursBates=PostHoc_Uniforme_t(delta,x,xnull,procedureBates,n_cal,n_test,m0,Oracle=Oracle)\n",
    "    \n",
    "    I_n=np.arange(n_cal+2)/(n_cal+1)\n",
    "    \n",
    "    t_max=int((n_cal+1)*Prop_t_max)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.rc('text.latex', preamble=r'\\usepackage{bm} ')\n",
    "    ep=2.5\n",
    "    fs=16\n",
    "    \n",
    "    \n",
    "    plt.plot(I_n[t_min:t_max],Maj_DKW_PostHoc[t_min:t_max],color=colors_blindness[1],label=r\"$\\overline{\\mathrm{FDP}}^{\\small \\mbox{DKW}}_{t,\\delta}:{ \\mbox{TwoClass}}$ (This work)\",linewidth=ep)\n",
    "    plt.plot(I_n[t_min:t_max],FDP[t_min:t_max],':',color=colors_blindness[1],label=r\"${\\mathrm{FDP}}(\\mathcal{R}(t)): \\mbox{TwoClass}$ (Adaptive score)\",linewidth=ep)\n",
    "    plt.plot(I_n[t_min:t_max],Maj_DKW_PostHocBates[t_min:t_max], color=colors_blindness[0],label=r\"$\\overline{\\mathrm{FDP}}^{\\small \\mbox{DKW}}_{t,\\delta}:{ \\mbox{OneClass}}$\",linewidth=ep)\n",
    "    plt.plot(I_n[t_min:t_max],FDPBates[t_min:t_max],':',color=colors_blindness[0],label=r\"${\\mathrm{FDP}}(\\mathcal{R}(t)): \\mbox{OneClass}$ (No-Adaptive score)\",linewidth=ep)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    for tickLabel in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "        tickLabel.set_fontsize(fs)\n",
    "    \n",
    "    deltaString=str(delta)\n",
    "    plt.xlabel(r\"Level $t$ of the threshold\",fontsize=fs)\n",
    "    plt.ylabel(\"Error Proportion\",fontsize=fs)\n",
    "    #plt.title(r\"Comparison of $\\mathrm{FDP}$ and $\\overline{\\mathrm{FDP}}_{\\delta}$ for a Novelty Detection task with $\\delta= $\"+deltaString, fontsize=fs)\n",
    "    plt.legend(fontsize=fs)\n",
    "    if SaveFig:\n",
    "        plt.savefig('PostHoc_D_'+str(m1)+'_'+str(m0)+'_'+str(n_cal)+'.pdf',format='pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    if VisualisationDouble:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.rc('text.latex', preamble=r'\\usepackage{bm} ')\n",
    "        ep=2.5\n",
    "        fs=16\n",
    "\n",
    "\n",
    "        plt.plot(I_n[t_min:t_max],Maj_DKW_PostHoc[t_min:t_max],color=colors_blindness[1],label=r\"$\\overline{\\mathrm{FDP}}^{\\small \\mbox{DKW}}_{t,\\delta}:{ \\mbox{TwoClass}}$ (This work)\",linewidth=ep)\n",
    "        plt.plot(I_n[t_min:t_max],FDP[t_min:t_max],':',color=colors_blindness[1],label=r\"${\\mathrm{FDP}}(\\mathcal{R}(t)): \\mbox{TwoClass}$ (Adaptive score)\",linewidth=ep)\n",
    "        plt.plot(I_n[t_min:t_max],Maj_DKW_PostHocBates[t_min:t_max], color=colors_blindness[0],label=r\"$\\overline{\\mathrm{FDP}}^{\\small \\mbox{DKW}}_{t,\\delta}:{ \\mbox{OneClass}}$\",linewidth=ep)\n",
    "        plt.plot(I_n[t_min:t_max],FDPBates[t_min:t_max],':',color=colors_blindness[0],label=r\"${\\mathrm{FDP}}(\\mathcal{R}(t)): \\mbox{OneClass}$ (No-Adaptive score)\",linewidth=ep)\n",
    "\n",
    "\n",
    "        plt.plot(I_n[t_min:t_max],Maj_Simes_PostHoc[t_min:t_max],'--',color=colors_blindness[1],label=r\"$\\overline{\\mathrm{FDP}}^{\\small \\mbox{Simes}}_{t,\\delta}:{ \\mbox{TwoClass}}$\",alpha=0.3,linewidth=ep)\n",
    "        plt.plot(I_n[t_min:t_max],Maj_Simes_PostHocBates[t_min:t_max],'--', color=colors_blindness[0],label=r\"$\\overline{\\mathrm{FDP}}^{\\small \\mbox{Simes}}_{t,\\delta}:{ \\mbox{OneClass}}$\",alpha=0.3,linewidth=ep)\n",
    "\n",
    "    \n",
    "    \n",
    "        for tickLabel in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "            tickLabel.set_fontsize(fs)\n",
    "\n",
    "        deltaString=str(delta)\n",
    "        plt.legend(fontsize=fs)\n",
    "        plt.xlabel(r\"Level $t$ of the threshold\",fontsize=fs)\n",
    "        plt.ylabel(\"Error Proportion\",fontsize=fs)\n",
    "        #plt.title(r\"Comparison of $\\mathrm{FDP}$ and $\\overline{\\mathrm{FDP}}_{\\delta}$ for a Novelty Detection task with $\\delta= $\"+deltaString, fontsize=fs)\n",
    "       \n",
    "        if SaveFig:\n",
    "            plt.savefig('PostHoc_D_'+str(m1)+'_'+str(m0)+'_'+str(n_cal)+'_Simes.pdf',format='pdf')\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.rc('text.latex', preamble=r'\\usepackage{bm} ')\n",
    "    \n",
    "    plt.plot(I_n[t_min:t_max],Rejet[t_min:t_max],color=colors_blindness[1],label=r\"$\\mathcal{R}(\\mbox(AD)_\\alpha)$\",linewidth=ep)\n",
    "    plt.plot(I_n[t_min:t_max],RejetBates[t_min:t_max],color=colors_blindness[0],label=r\"$\\mathcal{R}(\\mbox(Bates)_\\alpha)$\",linewidth=ep)\n",
    "    plt.xlabel(r\"Level $\\alpha$ of test $\\mathrm{FDR}=\\alpha$\",fontsize=fs)\n",
    "    plt.ylabel(\"Number of rejection\",fontsize=fs)\n",
    "    plt.legend(fontsize=fs)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return (FDP,Rejet,Maj_DKW_PostHoc,Maj_Simes_PostHoc,m0_Hat_DKW,m0_Hat_Simes,FDPBates,RejetBates,Maj_DKW_PostHocBates,Maj_Simes_PostHocBates,m0_Hat_DKWBates,m0_Hat_SimesBates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cca7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c4977",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ComparisonUniformePostHoc(delta,xShuttle,xnullShuttle,procShuttle,procBatesShuttle,n_calShuttle,n_testShuttle,m0Shuttle,m1Shuttle,t_min=1,Prop_t_max=0.2, VisualisationDouble=True,Oracle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2530f5",
   "metadata": {},
   "source": [
    "## Ada Detect Procedure and Post Hoc: $\\mathrm{FDR}\\leq \\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9797e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the FDP, the TDP, and all the PostHoc bounds at level delta for a procedure of novelty detection wich control the FDR at level alpha. \n",
    "\n",
    "def Maj_PostHocAdaDetect(delta,x,xnull,procedure,n_cal,n_test,m0,m1,NotAdaptive_m0=False):\n",
    "    \n",
    "    procedure.fit(x,0.5,xnull)\n",
    "    \n",
    "    n=n_cal\n",
    "    m=n_test\n",
    "    print('m0:' +str(m0))\n",
    "    \n",
    "\n",
    "    FDP=np.zeros(n+2)\n",
    "    kBH=np.zeros(n+2)\n",
    "    TDP=np.zeros(n+2)\n",
    "    I_n=np.arange(n+2)/(n+1)\n",
    "    \n",
    "    \n",
    "    pValeurs=np.array([compute_pvalue(x, procedure.null_statistics) for x in procedure.test_statistics])\n",
    "    \n",
    "    (m0_Hat_DKW,m0_Hat_Simes,V,DevDKWBound)=m0Adaptatif(delta,pValeurs,n_cal,n_test)\n",
    "    \n",
    "    #FDP Computation\n",
    "    \n",
    "    for i in range (n+2):\n",
    "        level=i/(n+1)\n",
    "        RejectionSet=EmpBH(procedure.null_statistics, procedure.test_statistics, level = i/(n+1))\n",
    "        kBH[i]=len(RejectionSet)\n",
    "        \n",
    "        FD=np.sum((RejectionSet<m0))\n",
    "        FDP[i]=FD/max(kBH[i],1)\n",
    "        TDP[i]=(kBH[i]-FD)/m1\n",
    "    \n",
    "    \n",
    "    #Post Hoc Bounds\n",
    "    \n",
    "\n",
    "    lamb=IterLambda_Tau(n_cal,m0_Hat_DKW,nIter)(delta)\n",
    "    Maj_DKW_PostHoc=np.minimum((m0_Hat_DKW*I_n*kBH/m+DevDKWBound)*(kBH>0)/(np.maximum(kBH,1)),1)\n",
    "     \n",
    "    Maj_Simes_PostHoc=np.minimum(m0_Hat_Simes*I_n*(kBH>0)/(m*delta),1)\n",
    "    \n",
    "    if NotAdaptive_m0:\n",
    "        lamb=IterLambda_Tau(n_cal,m,nIter)(delta)\n",
    "        Maj_DKW_PostHocNoAdapt=np.minimum((I_n*kBH+m*lamb)*(kBH>0)/(np.maximum(kBH,1)),1)\n",
    " \n",
    "        Maj_Simes_PostHocNoAdapt=np.minimum(I_n*(kBH>0)/(delta),1)\n",
    "    \n",
    "        return(FDP,TDP,kBH,Maj_DKW_PostHoc,Maj_DKW_PostHocNoAdapt,Maj_Simes_PostHoc,Maj_Simes_PostHocNoAdapt,m0_Hat_DKW,m0_Hat_Simes)\n",
    "    \n",
    "    \n",
    "    return(FDP,TDP,kBH,Maj_DKW_PostHoc,Maj_Simes_PostHoc,m0_Hat_DKW,m0_Hat_Simes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee1a4fd",
   "metadata": {},
   "source": [
    "### Comparison of the performance for One Class Clasification V Two Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939738a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the graph to compare the effiency of using adpative score or not.\n",
    "\n",
    "def Graph_PostHocComparison_AdaptiveScores(n_cal,m0,m1,FDP,TDP,kBH,Maj_DKW_PostHoc,Maj_Simes_PostHoc,m0_Hat,m0_Hat_Simes,FDPBates,TDPBates,kBHBates,Maj_DKW_PostHocBates,Maj_Simes_PostHocBates,m0_HatBates,m0_Hat_SimesBates,Amin=1,Prop_Amax=0.2,VisualisationDouble=False,SaveFig=False,Subplot_TDP=False):\n",
    "    \n",
    "    ep=2.5\n",
    "    fs=16  \n",
    "    \n",
    "    if Subplot_TDP:\n",
    "        ep=4\n",
    "        fs=24\n",
    "\n",
    "    Amax=int((n_cal+1)*Prop_Amax)\n",
    "    \n",
    "    if Subplot_TDP:\n",
    "        plt.figure(1,figsize=(30,15))\n",
    "    if not Subplot_TDP:\n",
    "        plt.figure(figsize=(10,10))\n",
    "    plt.rc('text.latex', preamble=r'\\usepackage{bm} ')\n",
    "\n",
    "\n",
    "\n",
    "    n=n_cal\n",
    "    \n",
    "    I_n=np.arange(n+2)/(n+1)\n",
    "    \n",
    "\n",
    "    \n",
    "    if Subplot_TDP:\n",
    "        plt.subplot(1,2,1)\n",
    "    \n",
    "    plt.plot(I_n[Amin:Amax],Maj_DKW_PostHoc[Amin:Amax],color=colors_blindness[1],label=r\"$\\overline{\\mathrm{FDP}}^{DKW}_{\\alpha,\\delta}:\\mbox{TwoClass}$ (This work)\",linewidth=ep)\n",
    "    plt.plot(I_n[Amin:Amax],FDP[Amin:Amax],':',color=colors_blindness[1],label=r\"$\\mathrm{FDP}(\\mbox{AD}_\\alpha):\\mbox{TwoClass}$\",linewidth=ep)\n",
    "    plt.plot(I_n[Amin:Amax],Maj_DKW_PostHocBates[Amin:Amax], color=colors_blindness[0],label=r\"$\\overline{\\mathrm{FDP}}^{DKW}_{\\alpha,\\delta}:\\mbox{OneClass}$ \",linewidth=ep)\n",
    "    plt.plot(I_n[Amin:Amax],FDPBates[Amin:Amax],':',color=colors_blindness[0],label=r\"$\\mathrm{FDP}(\\mbox{OneClass}_\\alpha):\\mbox{OneClass}$\",linewidth=ep)\n",
    "    plt.legend(loc='upper right',fontsize=fs)\n",
    "    plt.xlabel(r\"Target $\\mathrm{FDR}$ level $\\alpha$\",fontsize=fs)\n",
    "    plt.ylabel(\"False Discovery Proportion\",fontsize=fs)\n",
    "    \n",
    "    \n",
    "    for tickLabel in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "        tickLabel.set_fontsize(fs)\n",
    "    \n",
    "    if Subplot_TDP:\n",
    "        plt.subplot(1,2,2)\n",
    "        \n",
    "        plt.plot(I_n[Amin:Amax],TDP[Amin:Amax],':',color=colors_blindness[1],label=r\"$\\mathrm{TDP}(\\mbox{AD}_\\alpha):\\mbox{TwoClass}$\",linewidth=ep)\n",
    "        plt.plot(I_n[Amin:Amax],TDPBates[Amin:Amax],':',color=colors_blindness[0],label=r\"$\\mathrm{TDP}(\\mbox{OneClass}_\\alpha):\\mbox{OneClass}$\",linewidth=ep) \n",
    "        \n",
    "        plt.legend(loc='upper right',fontsize=fs)   \n",
    "        plt.xlabel(r\"Target $\\mathrm{FDR}$ level $\\alpha$\",fontsize=fs)\n",
    "        plt.ylabel(\"True Discovery Proportion\",fontsize=fs)\n",
    "    \n",
    "    \n",
    "        for tickLabel in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "            tickLabel.set_fontsize(fs)\n",
    "    \n",
    "    if SaveFig:\n",
    "        plt.savefig('PostHoc_FDR_D_'+str(m1)+'_'+str(m0)+'_'+str(n_cal)+'.pdf',format='pdf')\n",
    "    \n",
    "    plt.show()\n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "    if VisualisationDouble:\n",
    "        \n",
    "        \n",
    "        \n",
    "        if Subplot_TDP:\n",
    "            plt.figure(2,figsize=(30,15))\n",
    "        if not Subplot_TDP:\n",
    "            plt.figure(figsize=(10,10))\n",
    "            \n",
    "        plt.rc('text.latex', preamble=r'\\usepackage{bm} ')\n",
    "\n",
    "        if Subplot_TDP:\n",
    "            plt.subplot(1,2,1)\n",
    "        \n",
    "        plt.plot(I_n[Amin:Amax],Maj_DKW_PostHoc[Amin:Amax],color=colors_blindness[1],label=r\"$\\overline{\\mathrm{FDP}}^{DKW}_{\\alpha,\\delta}:\\mbox{TwoClass}$ (This work)\",linewidth=ep)\n",
    "        plt.plot(I_n[Amin:Amax],FDP[Amin:Amax],':',color=colors_blindness[1],label=r\"$\\mathrm{FDP}(\\mbox{AD}_\\alpha):\\mbox{TwoClass}$\",linewidth=ep)\n",
    "        plt.plot(I_n[Amin:Amax],Maj_DKW_PostHocBates[Amin:Amax], color=colors_blindness[0],label=r\"$\\overline{\\mathrm{FDP}}^{DKW}_{\\alpha,\\delta}:\\mbox{OneClass}$ \",linewidth=ep)\n",
    "        plt.plot(I_n[Amin:Amax],FDPBates[Amin:Amax],':',color=colors_blindness[0],label=r\"$\\mathrm{FDP}(\\mbox{OneClass}_\\alpha):\\mbox{OneClass}$\",linewidth=ep)\n",
    "\n",
    "        \n",
    "        plt.plot(I_n[Amin:Amax],Maj_Simes_PostHoc[Amin:Amax],'--',color=colors_blindness[1],label=r\"$\\overline{\\mathrm{FDP}}^{Simes}_{\\delta}(\\mbox{AD}_\\alpha):\\mbox{TwoClass}$\",alpha=0.3,linewidth=ep)\n",
    "        plt.plot(I_n[Amin:Amax],Maj_Simes_PostHocBates[Amin:Amax],'--', color=colors_blindness[0],label=r\"$\\overline{\\mathrm{FDP}}^{Simes}_{\\delta}(\\mbox{OneClass}_\\alpha):\\mbox{OneClass}$\",alpha=0.3,linewidth=ep)\n",
    "    \n",
    "\n",
    "        plt.legend(loc='upper right',fontsize=fs)\n",
    "        plt.xlabel(r\"Target $\\mathrm{FDR}$ level $\\alpha$\",fontsize=fs)\n",
    "        plt.ylabel(\"False Discovery Proportion\",fontsize=fs)\n",
    "       \n",
    "        for tickLabel in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "            tickLabel.set_fontsize(fs)\n",
    "    \n",
    "    \n",
    "        if Subplot_TDP:\n",
    "            plt.subplot(1,2,2)\n",
    "\n",
    "            plt.plot(I_n[Amin:Amax],TDP[Amin:Amax],':',color=colors_blindness[1],label=r\"$\\mathrm{TDP}(\\mbox{AD}_\\alpha):\\mbox{TwoClass}$\",linewidth=ep)\n",
    "            plt.plot(I_n[Amin:Amax],TDPBates[Amin:Amax],':',color=colors_blindness[0],label=r\"$\\mathrm{TDP}(\\mbox{OneClass}_\\alpha):\\mbox{OneClass}$\",linewidth=ep) \n",
    "\n",
    "            plt.legend(loc='upper right',fontsize=fs)   \n",
    "            plt.xlabel(r\"Target $\\mathrm{FDR}$ level $\\alpha$\",fontsize=fs)\n",
    "            plt.ylabel(\"True Discovery Proportion\",fontsize=fs)\n",
    "\n",
    "            for tickLabel in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "                tickLabel.set_fontsize(fs)\n",
    "\n",
    "            \n",
    "            \n",
    "        if SaveFig:\n",
    "            plt.savefig('PostHoc_FDR_D_'+str(m1)+'_'+str(m0)+'_'+str(n_cal)+'_Simes.pdf',format='pdf')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.rc('text.latex', preamble=r'\\usepackage{bm} ')\n",
    "    \n",
    "    plt.plot(I_n[Amin:Amax],kBH[Amin:Amax],color=colors_blindness[1],label=r\"$\\mathcal{R}(\\mbox(AD)_\\alpha):\\mbox{TwoClass}$\",linewidth=ep)\n",
    "    plt.plot(I_n[Amin:Amax],kBHBates[Amin:Amax],color=colors_blindness[0],label=r\"$\\mathcal{R}(\\mbox{OneClass}_\\alpha):\\mbox{OneClass}$\",linewidth=ep)\n",
    "    plt.xlabel(r\"Target $\\mathrm{FDR}$ level $\\alpha$\",fontsize=fs)\n",
    "    plt.ylabel(\"Number of rejection\",fontsize=fs)\n",
    "    plt.legend(fontsize=fs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b92a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comparison_AdaptiveScores(delta,x,xnull,procedure,procedureBates,n_cal,m1,m0,\n",
    "                              Amin=1,Prop_Amax=0.2,\n",
    "                              VisualisationDouble=False,SaveFig=False,Subplot_TDP=False):\n",
    "    \n",
    "    \n",
    "    n_test=m1+m0\n",
    "    FDP,TDP,kBH,Maj_DKW_PostHoc,Maj_Simes_PostHoc,m0_Hat_DKW,m0_Hat_Simes=Maj_PostHocAdaDetect(delta,x,xnull,procedure,n_cal,n_test,m0,m1)\n",
    "    FDPBates,TDPBates,kBHBates,Maj_DKW_PostHocBates,Maj_Simes_PostHocBates,m0_Hat_DKWBates,m0_Hat_SimesBates=Maj_PostHocAdaDetect(delta,x,xnull,procedureBates,n_cal,n_test,m0,m1)\n",
    "    \n",
    "    Graph_PostHocComparison_AdaptiveScores(n_cal,m0,m1,FDP,TDP,kBH,Maj_DKW_PostHoc,Maj_Simes_PostHoc,m0_Hat_DKW,m0_Hat_Simes,FDPBates,TDPBates,kBHBates,Maj_DKW_PostHocBates,Maj_Simes_PostHocBates,m0_Hat_DKWBates,m0_Hat_SimesBates,Amin,Prop_Amax,VisualisationDouble,SaveFig,Subplot_TDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c423aa3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Comparison_AdaptiveScores(delta,xShuttle,xnullShuttle,procShuttle,procBatesShuttle,n_calShuttle,m1Shuttle,m0Shuttle,\n",
    "                              Amin=1,Prop_Amax=0.2,\n",
    "                              VisualisationDouble=True,Subplot_TDP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5403e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison_AdaptiveScores(delta,xShuttle,xnullShuttle,procShuttle,procBatesShuttle,n_calShuttle,m1Shuttle,m0Shuttle,\n",
    "                              Amin=1,Prop_Amax=0.2,\n",
    "                              VisualisationDouble=True,Subplot_TDP=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ea2f4a",
   "metadata": {},
   "source": [
    "### Effect of using $\\hat{m}_0$ instead of $m$ in the PostHoc bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Graph_PostHoc_Comparison_m0Hat(n_cal,m0,m1,delta,FDP,Maj_DKW_PostHoc,Maj_DKW_PostHocNoAdapt,Maj_Simes_PostHoc,Maj_Simes_PostHocNoAdapt,Amin=1,Prop_Amax=0.2,SaveFig=False):\n",
    "    ep=2.5\n",
    "    fs=16  \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.rc('text.latex', preamble=r'\\usepackage{bm} ')\n",
    "    \n",
    "    \n",
    "    Amax=int((n_cal+1)*Prop_Amax)\n",
    "    n=n_cal\n",
    "    I_n=np.arange(n+2)/(n+1)\n",
    "    \n",
    "    plt.plot(I_n[Amin:Amax],FDP[Amin:Amax],':',color=colors_blindness[1],label=r\"$\\mathrm{FDP}(\\mbox{AD}_\\alpha)$\",linewidth=ep)\n",
    "    \n",
    "\n",
    "    plt.plot(I_n[Amin:Amax],Maj_DKW_PostHoc[Amin:Amax],color=colors_blindness[1],label=r\"$\\overline{\\mathrm{FDP}}^{DKW}_{\\alpha,\\delta}$ with $m_0$ estimation\",linewidth=ep)\n",
    "    plt.plot(I_n[Amin:Amax],Maj_Simes_PostHoc[Amin:Amax],'--',color=colors_blindness[1],label=r\"$\\overline{\\mathrm{FDP}}^{Simes}_{\\delta}(\\mbox{AD}_\\alpha)$ with $m_0$ estimation\",linewidth=ep)\n",
    "        \n",
    "        \n",
    "    plt.plot(I_n[Amin:Amax],Maj_DKW_PostHocNoAdapt[Amin:Amax],color=colors_blindness[0],label=r\"$\\overline{\\mathrm{FDP}}^{DKW}_{\\alpha,\\delta}$ without $m_0$ estimation\",linewidth=ep)\n",
    "    plt.plot(I_n[Amin:Amax],Maj_Simes_PostHocNoAdapt[Amin:Amax],'--',color=colors_blindness[0],label=r\"$\\overline{\\mathrm{FDP}}^{Simes}_{\\delta}(\\mbox{AD}_\\alpha)$ without $m_0$ estimation\",linewidth=ep)\n",
    "    \n",
    "    plt.legend(loc='upper right',fontsize=fs)\n",
    "    plt.xlabel(r\"Target $\\mathrm{FDR}$ level $\\alpha$\",fontsize=fs)\n",
    "    plt.ylabel(\"False Discovery Proportion\",fontsize=fs)\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "    for tickLabel in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "        tickLabel.set_fontsize(fs)\n",
    "\n",
    "    if SaveFig:\n",
    "        plt.savefig('PostHoc_m0Adapt_D_'+str(m1)+'_'+str(m0)+'_'+str(n_cal)+'_Simes.pdf',format='pdf')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comparison_m0Hat(delta,x,xnull,procedure,n_cal,m1,m0,\n",
    "                              Amin=1,Prop_Amax=0.2,SaveFig=False):\n",
    "    \n",
    "    n_test=m0+m1\n",
    "    \n",
    "    (FDP,TDP,kBH,Maj_DKW_PostHoc,Maj_DKW_PostHocNoAdapt,Maj_Simes_PostHoc,Maj_Simes_PostHocNoAdapt,m0_Hat_DKW,m0_Hat_Simes)=Maj_PostHocAdaDetect(delta,x,xnull,procedure,n_cal,n_test,m0,m1,NotAdaptive_m0=True)\n",
    "    \n",
    "    Graph_PostHoc_Comparison_m0Hat(n_cal,m0,m1,delta,FDP,Maj_DKW_PostHoc,Maj_DKW_PostHocNoAdapt,Maj_Simes_PostHoc,Maj_Simes_PostHocNoAdapt,Amin,Prop_Amax,SaveFig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison_m0Hat(delta,xShuttle,xnullShuttle,procShuttle,n_calShuttle,m1Shuttle,m0Shuttle,\n",
    "                              Amin=1,Prop_Amax=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30378bb3",
   "metadata": {},
   "source": [
    "### Effect of $\\delta$ in the PostHoc bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Maj_PostHocAdaDetect_Diff_Delta(Delta,x,xnull,procedure,n_cal,n_test,m0,m1):\n",
    "    \n",
    "    procedure.fit(x,0.5,xnull)\n",
    "    \n",
    "    N=len(Delta)\n",
    "    n=n_cal\n",
    "    m=n_test\n",
    "    print('m0:' +str(m0))\n",
    "    \n",
    "\n",
    "    FDP=np.zeros(n+2)\n",
    "    kBH=np.zeros(n+2)\n",
    "    TDP=np.zeros(n+2)\n",
    "    I_n=np.arange(n+2)/(n+1)\n",
    "    \n",
    "    Maj_DKW_PostHoc=np.zeros((N,n+2))\n",
    "    Maj_Simes_PostHoc=np.zeros((N,n+2))\n",
    "    \n",
    "    \n",
    "    pValeurs=np.array([compute_pvalue(x, procedure.null_statistics) for x in procedure.test_statistics])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range (n+2):\n",
    "        level=i/(n+1)\n",
    "        RejectionSet=EmpBH(procedure.null_statistics, procedure.test_statistics, level = i/(n+1))\n",
    "        kBH[i]=len(RejectionSet)\n",
    "        \n",
    "        FD=np.sum((RejectionSet<m0))\n",
    "        FDP[i]=FD/max(kBH[i],1)\n",
    "        TDP[i]=(kBH[i]-FD)/m1\n",
    "    \n",
    "    for j in range (N):\n",
    "        delta=Delta[j]\n",
    "    \n",
    "        (m0_Hat_DKW,m0_Hat_Simes,V,DevDKWBound)=m0Adaptatif(delta,pValeurs,n_cal,n_test,False)\n",
    "        #Post Hoc Bounds\n",
    "        \n",
    "        Maj_DKW_PostHoc[j]=np.minimum((m0_Hat_DKW*I_n*kBH/m+DevDKWBound)*(kBH>0)/(np.maximum(kBH,1)),1)\n",
    "        Maj_Simes_PostHoc[j]=np.minimum(m0_Hat_Simes*I_n*(kBH>0)/(m*delta),1)\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "    return(FDP,TDP,kBH,Maj_DKW_PostHoc,Maj_Simes_PostHoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3210f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Graph_PostHoc_Comparison_Delta(n_cal,m0,m1,Delta,FDP,Maj_DKW_PostHoc,Maj_Simes_PostHoc,Amin=1,Prop_Amax=0.2,Comparison_02=False,SaveFig=False):\n",
    "    ep=2.5\n",
    "    fs=16  \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.rc('text.latex', preamble=r'\\usepackage{bm} ')\n",
    "    \n",
    "    \n",
    "    Amax=int((n_cal+1)*Prop_Amax)\n",
    "    n=n_cal\n",
    "    N=len(Delta)\n",
    "    I_n=np.arange(n+2)/(n+1)\n",
    "    \n",
    "    if Comparison_02:\n",
    "        N=N-1\n",
    "    \n",
    "    plt.plot(I_n[Amin:Amax],FDP[Amin:Amax],':',color=colors_blindness[1],label=r\"$\\mathrm{FDP}(\\mbox{AD}_\\alpha)$\",linewidth=ep)\n",
    "    \n",
    "    for j in range (N):\n",
    "        deltaString=str(Delta[j])\n",
    "        plt.plot(I_n[Amin:Amax],Maj_DKW_PostHoc[j,Amin:Amax],color=colors_blindness[j],label=r\"$\\overline{\\mathrm{FDP}}^{DKW}_{\\alpha,\\delta}$. $\\delta=$\"+deltaString,linewidth=ep)\n",
    "        plt.plot(I_n[Amin:Amax],Maj_Simes_PostHoc[j,Amin:Amax],'--',color=colors_blindness[j],label=r\"$\\overline{\\mathrm{FDP}}^{Simes}_{\\delta}(\\mbox{AD}_\\alpha)$. $\\delta=$\"+deltaString,linewidth=ep)\n",
    "        \n",
    "    if Comparison_02:\n",
    "        deltaString=str(Delta[N])\n",
    "        plt.plot(I_n[Amin:Amax],Maj_DKW_PostHoc[N,Amin:Amax],color=colors_blindness[1],label=r\"$\\overline{\\mathrm{FDP}}^{DKW}_{\\alpha,\\delta}$. $\\delta=$\"+deltaString,linewidth=ep)\n",
    "        plt.plot(I_n[Amin:Amax],Maj_Simes_PostHoc[N,Amin:Amax],'--',color=colors_blindness[1],label=r\"$\\overline{\\mathrm{FDP}}^{Simes}_{\\delta}(\\mbox{AD}_\\alpha)$. $\\delta=$\"+deltaString,linewidth=ep)\n",
    "        \n",
    "        \n",
    "    plt.legend(loc='upper right',fontsize=fs)\n",
    "    plt.xlabel(r\"Target $\\mathrm{FDR}$ level $\\alpha$\",fontsize=fs)\n",
    "    plt.ylabel(\"False Discovery Proportion\",fontsize=fs)\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "    for tickLabel in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "        tickLabel.set_fontsize(fs)\n",
    "\n",
    "    if SaveFig:\n",
    "        plt.savefig('PostHoc_Delta_D_'+str(m1)+'_'+str(m0)+'_'+str(n_cal)+'_Simes.pdf',format='pdf')\n",
    "\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comparison_Delta(Delta,x,xnull,procedure,n_cal,m1,m0,Comparison_02=False,\n",
    "                              Amin=1,Prop_Amax=0.2,SaveFig=False):\n",
    "    n_test=m1+m0\n",
    "    \n",
    "    if Comparison_02:\n",
    "        Delta=np.append(Delta,0.2)\n",
    "    \n",
    "    FDP,TDP,kBH,Maj_DKW_PostHoc,Maj_Simes_PostHoc=Maj_PostHocAdaDetect_Diff_Delta(Delta,x,xnull,procedure,n_cal,n_test,m0,m1)\n",
    "    \n",
    "    Graph_PostHoc_Comparison_Delta(n_cal,m0,m1,Delta,FDP,Maj_DKW_PostHoc,Maj_Simes_PostHoc,Amin,Prop_Amax,Comparison_02,SaveFig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c037927",
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta=np.array([0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a239f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison_Delta(Delta,xShuttle,xnullShuttle,procShuttle,n_calShuttle,m1Shuttle,m0Shuttle,\n",
    "                              Amin=1,Prop_Amax=0.2,Comparison_02=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d928c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeltaBis=np.array([0.05,0.1,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3aacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison_Delta(DeltaBis,xShuttle,xnullShuttle,procShuttle,n_calShuttle,m1Shuttle,m0Shuttle,\n",
    "                              Amin=1,Prop_Amax=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1928977f",
   "metadata": {},
   "source": [
    "## Experiment with different data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc348756",
   "metadata": {},
   "source": [
    "### Credit Card Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetCreditCard = fetch_openml(name='creditcard', version=1, as_frame=False)\n",
    "XCreditCard = datasetCreditCard.data\n",
    "yCreditCard = datasetCreditCard.target.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af80c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test sample \n",
    "outlrCreditCard, inlrCreditCard = XCreditCard[yCreditCard==1], XCreditCard[yCreditCard==0]\n",
    "\n",
    "np.random.shuffle(outlrCreditCard)\n",
    "np.random.shuffle(inlrCreditCard)\n",
    "\n",
    "m1CreditCard = 260\n",
    "m0CreditCard = 500\n",
    "test1CreditCard, test0CreditCard = outlrCreditCard[:m1CreditCard], inlrCreditCard[:m0CreditCard]\n",
    "xCreditCard = np.concatenate([test0CreditCard, test1CreditCard]) \n",
    "n_testCreditCard=m1CreditCard+m0CreditCard\n",
    "print(m0CreditCard/(m1CreditCard+m0CreditCard))\n",
    "#NTS\n",
    "nCreditCard=3000\n",
    "SplitSizeCreditCard=2000/3000\n",
    "n_trainCreditCard=int(SplitSizeCreditCard*nCreditCard)\n",
    "n_calCreditCard=nCreditCard-n_trainCreditCard\n",
    "\n",
    "\n",
    "xnullCreditCard = inlrCreditCard[m0CreditCard:m0CreditCard+nCreditCard]\n",
    "\n",
    "\n",
    "procCreditCard = AdaDetectERM(scoring_fn = RandomForestClassifier(max_depth=10),\n",
    "                                 split_size=SplitSizeCreditCard) \n",
    "procBatesCreditCard=AdaDetectDE(scoring_fn = OCC(scoring_fn = IsolationForest(contamination=0.1)), f0_known = False,\n",
    "                            split_size=SplitSizeCreditCard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison_AdaptiveScores(delta,xCreditCard,xnullCreditCard,procCreditCard,procBatesCreditCard,n_calCreditCard,m1CreditCard,m0CreditCard,\n",
    "                              Amin=1,Prop_Amax=0.2,\n",
    "                              VisualisationDouble=True,Subplot_TDP=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba015b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison_m0Hat(delta,xCreditCard,xnullCreditCard,procCreditCard,n_calCreditCard,m1CreditCard,m0CreditCard,\n",
    "                              Amin=1,Prop_Amax=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison_Delta(Delta,xCreditCard,xnullCreditCard,procCreditCard,n_calCreditCard,m1CreditCard,m0CreditCard,\n",
    "                              Amin=1,Prop_Amax=0.2,Comparison_02=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e7dc9d",
   "metadata": {},
   "source": [
    "### Mammography Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9606f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetMam = fetch_openml(name='mammography', version=1, as_frame=False)\n",
    "XMam = datasetMam.data\n",
    "yMam = datasetMam.target.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2058b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test sample \n",
    "outlrMam, inlrMam = XMam[yMam==1], XMam[yMam==-1]\n",
    "\n",
    "np.random.shuffle(outlrMam)\n",
    "np.random.shuffle(inlrMam)\n",
    "\n",
    "\n",
    "\n",
    "m1Mam = 260\n",
    "m0Mam = 500\n",
    "\n",
    "\n",
    "\n",
    "test1Mam, test0Mam = outlrMam[:m1Mam], inlrMam[:m0Mam]\n",
    "xMam = np.concatenate([test0Mam, test1Mam]) \n",
    "n_testMam=m1Mam+m0Mam\n",
    "print(m0Mam/(m1Mam+m0Mam))\n",
    "#NTS\n",
    "nMam=3000\n",
    "SplitSizeMam=2000/3000\n",
    "n_trainMam=int(SplitSizeMam*nMam)\n",
    "n_calMam=nMam-n_trainMam\n",
    "\n",
    "\n",
    "xnullMam = inlrMam[m0Mam:m0Mam+nMam]\n",
    "\n",
    "\n",
    "\n",
    "procMam = AdaDetectERM(scoring_fn = RandomForestClassifier(max_depth=10),\n",
    "                                 split_size=SplitSizeMam) \n",
    "procBatesMam=AdaDetectDE(scoring_fn = OCC(scoring_fn = IsolationForest(contamination=0.1)), f0_known = False,\n",
    "                            split_size=SplitSizeMam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a7ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison_AdaptiveScores(delta,xMam,xnullMam,procMam,procBatesMam,n_calMam,m1Mam,m0Mam,\n",
    "                              Amin=1,Prop_Amax=0.2,\n",
    "                              VisualisationDouble=True,Subplot_TDP=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b59e47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Comparison_m0Hat(delta,xMam,xnullMam,procMam,n_calMam,m1Mam,m0Mam,\n",
    "                              Amin=1,Prop_Amax=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8bb566",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison_Delta(Delta,xMam,xnullMam,procMam,n_calMam,m1Mam,m0Mam,\n",
    "                              Amin=1,Prop_Amax=0.2,Comparison_02=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca25d2",
   "metadata": {},
   "source": [
    "# Tightness of the DKW-type Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465f43e",
   "metadata": {},
   "source": [
    "## Comparison between $\\mathbb{P}\\left(\\sup_{t\\in[0,1]}\\left(\\hat{F}_m(t)-I_n(t)\\right) >\\lambda\\right)$ and $B^{{{ DKW}}}(\\lambda,n,m)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41174722",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the Bound\n",
    "\n",
    "def DKW_Full(n,m):\n",
    "    def Bound_DKW(lamb):\n",
    "        t_nm=(n*m)/(n+m)\n",
    "        Num=2*np.sqrt(2*np.pi)*lamb*t_nm\n",
    "        Den=np.sqrt(n+m)\n",
    "        return np.minimum((1+Num/Den)*np.exp(-2*t_nm*lamb**2),1)\n",
    "    return Bound_DKW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1777323",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=500\n",
    "m=100\n",
    "N=10**4\n",
    "l=np.linspace(0.01,0.25,10**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fcb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Show_Tightness_DKW_Full(n,m,l,N,SaveFig=False):\n",
    "    \n",
    "    \n",
    "    ep=2.5\n",
    "    fs=16  \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.rc('text.latex', preamble=r'\\usepackage{bm} \\usepackage{amsfonts} ')\n",
    "    \n",
    "    B_DKW=DKW_Full(n,m)(l)\n",
    "    pValues=Simu_EmpiricalPvalues(n,m,N)\n",
    "    Prop=np.ones(m)/m\n",
    "    nn=(np.arange(n+1)+1)/(n+1)\n",
    "    TabMaxCDF=np.zeros(N)\n",
    "    for i in range (N):\n",
    "        F_m=stat.rv_discrete(values=np.array([pValues[i],Prop])).cdf(nn)\n",
    "        TabMaxCDF[i]=np.max((F_m-nn))\n",
    "        #print(TabMaxCDF)\n",
    "    r=len(l)\n",
    "    CourbesPropRespectDKW=np.zeros(r)\n",
    "    for i in range (r):\n",
    "        CourbesPropRespectDKW[i]=np.sum(TabMaxCDF>l[i])/N\n",
    "    plt.plot(l,CourbesPropRespectDKW,color=colors_blindness[0],label=r'Estimation of $\\mathbb{P}\\left(\\sup_{t\\in[0,1]}\\left(\\hat{F}_m(t)-I_n(t)\\right) >\\lambda\\right)$',linewidth=ep)\n",
    "    plt.plot(l,B_DKW,color=colors_blindness[1],label=r\"$B^{{{ DKW}}}(\\lambda,n,m)$\",linewidth=ep)\n",
    "    plt.xlabel(r\"$\\lambda$\",fontsize=fs)\n",
    "    plt.title(r\" n= \"+str(n)+ \" and m= \"+str(m),fontsize=18)\n",
    "    plt.legend(fontsize=fs)\n",
    "    \n",
    "    \n",
    "    if SaveFig:\n",
    "        plt.savefig('Tightness_DKW_Full'+'_'+str(n)+'_'+str(m)+'.pdf',format='pdf')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c075d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_Tightness_DKW_Full(n,m,l,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356dd2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_Tightness_DKW_Full(n,500,l,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575acac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Show_Tightness_DKW_Full(1000,500,l,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b82119",
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_Tightness_DKW_Full(100,100,l,N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
